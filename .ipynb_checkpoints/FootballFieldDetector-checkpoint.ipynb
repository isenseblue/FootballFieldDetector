{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "#Reading the video\n",
    "\n",
    "\n",
    "vidcap = cv2.VideoCapture(0)\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "success = True\n",
    "idx = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:\\\\ComputerVision\\\\computer-vision\\\\3_1YOLO\\\\home\\\\VideoTobe\\\\ADemo3.mp4', 'E:\\\\ComputerVision\\\\computer-vision\\\\3_1YOLO\\\\home\\\\VideoTobe\\\\ADemoV7 (1).mp4', 'E:\\\\ComputerVision\\\\computer-vision\\\\3_1YOLO\\\\home\\\\VideoTobe\\\\ADemoV7 (2).mp4', 'E:\\\\ComputerVision\\\\computer-vision\\\\3_1YOLO\\\\home\\\\VideoTobe\\\\ADemoV7 (3).mp4', 'E:\\\\ComputerVision\\\\computer-vision\\\\3_1YOLO\\\\home\\\\VideoTobe\\\\ADemoV7 (5).mp4', 'E:\\\\ComputerVision\\\\computer-vision\\\\3_1YOLO\\\\home\\\\VideoTobe\\\\ADemoV7.mp4', 'E:\\\\ComputerVision\\\\computer-vision\\\\3_1YOLO\\\\home\\\\VideoTobe\\\\Demo1.mp4', 'E:\\\\ComputerVision\\\\computer-vision\\\\3_1YOLO\\\\home\\\\VideoTobe\\\\demo2.mp4', 'E:\\\\ComputerVision\\\\computer-vision\\\\3_1YOLO\\\\home\\\\VideoTobe\\\\Demo4.mp4']\n"
     ]
    }
   ],
   "source": [
    "pathVideo = r\"Messi.mp4\"\n",
    "path = r\"E:\\ComputerVision\\computer-vision\\3_1YOLO\\home\\VideoTobe\"\n",
    "pathFoot = r\"E:\\ComputerVision\\computer-vision\\3_1YOLO\\home\\VideoTobe\\ADemoV7.mp4\"\n",
    "import glob\n",
    "v = glob.glob(path+'\\*.mp4')\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PathFoot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-64617e2f720e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#Reading the video\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mvidcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPathFoot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvidcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PathFoot' is not defined"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Reading the video\n",
    "vidcap = cv2.VideoCapture(PathFoot)\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "success = True\n",
    "idx = 0\n",
    "\n",
    "#Read the video frame by frame\n",
    "while success:\n",
    "    #converting into hsv image\n",
    "    hsv = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "    #green range\n",
    "    lower_green = np.array([40,40, 40])\n",
    "    upper_green = np.array([70, 255, 255])\n",
    "    #blue range\n",
    "    lower_blue = np.array([110,50,50])\n",
    "    upper_blue = np.array([130,255,255])\n",
    "\n",
    "    #Red range\n",
    "    lower_red = np.array([0,31,255])\n",
    "    upper_red = np.array([176,255,255])\n",
    "\n",
    "    #white range\n",
    "    lower_white = np.array([0,0,0])\n",
    "    upper_white = np.array([0,0,255])\n",
    "\n",
    "    #Define a mask ranging from lower to uppper\n",
    "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    #Do masking\n",
    "    res = cv2.bitwise_and(image, image, mask=mask)\n",
    "    #convert to hsv to gray\n",
    "    res_bgr = cv2.cvtColor(res,cv2.COLOR_HSV2BGR)\n",
    "    res_gray = cv2.cvtColor(res,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #Defining a kernel to do morphological operation in threshold image to \n",
    "    #get better output.\n",
    "    kernel = np.ones((13,13),np.uint8)\n",
    "    thresh = cv2.threshold(res_gray,127,255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "\n",
    "    #find contours in threshold image     \n",
    "    im2,contours,hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "    prev = 0\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    \n",
    "    for c in contours:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "\n",
    "        #Detect players\n",
    "        if(h>=(1.5)*w):\n",
    "            if(w>15 and h>= 15):\n",
    "                idx = idx+1\n",
    "                player_img = image[y:y+h,x:x+w]\n",
    "                player_hsv = cv2.cvtColor(player_img,cv2.COLOR_BGR2HSV)\n",
    "                #If player has blue jersy\n",
    "                mask1 = cv2.inRange(player_hsv, lower_blue, upper_blue)\n",
    "                res1 = cv2.bitwise_and(player_img, player_img, mask=mask1)\n",
    "                res1 = cv2.cvtColor(res1,cv2.COLOR_HSV2BGR)\n",
    "                res1 = cv2.cvtColor(res1,cv2.COLOR_BGR2GRAY)\n",
    "                nzCount = cv2.countNonZero(res1)\n",
    "                #If player has red jersy\n",
    "                mask2 = cv2.inRange(player_hsv, lower_red, upper_red)\n",
    "                res2 = cv2.bitwise_and(player_img, player_img, mask=mask2)\n",
    "                res2 = cv2.cvtColor(res2,cv2.COLOR_HSV2BGR)\n",
    "                res2 = cv2.cvtColor(res2,cv2.COLOR_BGR2GRAY)\n",
    "                nzCountred = cv2.countNonZero(res2)\n",
    "\n",
    "                if(nzCount >= 20):\n",
    "                    #Mark blue jersy players as france\n",
    "                    cv2.putText(image, 'France', (x-2, y-2), font, 0.8, (255,0,0), 2, cv2.LINE_AA)\n",
    "                    cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,0),3)\n",
    "                else:\n",
    "                    pass\n",
    "                if(nzCountred>=20):\n",
    "                    #Mark red jersy players as belgium\n",
    "                    cv2.putText(image, 'Belgium', (x-2, y-2), font, 0.8, (0,0,255), 2, cv2.LINE_AA)\n",
    "                    cv2.rectangle(image,(x,y),(x+w,y+h),(0,0,255),3)\n",
    "                else:\n",
    "                    pass\n",
    "        if((h>=1 and w>=1) and (h<=30 and w<=30)):\n",
    "            player_img = image[y:y+h,x:x+w]\n",
    "\n",
    "            player_hsv = cv2.cvtColor(player_img,cv2.COLOR_BGR2HSV)\n",
    "            #white ball  detection\n",
    "            mask1 = cv2.inRange(player_hsv, lower_white, upper_white)\n",
    "            res1 = cv2.bitwise_and(player_img, player_img, mask=mask1)\n",
    "            res1 = cv2.cvtColor(res1,cv2.COLOR_HSV2BGR)\n",
    "            res1 = cv2.cvtColor(res1,cv2.COLOR_BGR2GRAY)\n",
    "            nzCount = cv2.countNonZero(res1)\n",
    "\n",
    "\n",
    "            if(nzCount >= 3):\n",
    "                # detect football\n",
    "                cv2.putText(image, 'football', (x-2, y-2), font, 0.8, (0,255,0), 2, cv2.LINE_AA)\n",
    "                cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),3)\n",
    "\n",
    "\n",
    "    #cv2.imwrite(\"./Cropped/frame%d.jpg\" % count, res)\n",
    "    print ('Read a new frame: ', success )    # save frame as JPEG file\t\n",
    "    count += 1\n",
    "    cv2.imshow('Match Detection',image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    success,image = vidcap.read()\n",
    "\n",
    "vidcap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeDetector:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def detect(self, c):\n",
    "        # initialize the shape name and approximate the contour\n",
    "        shape = \"unidentified\"\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.04 * peri, True)\n",
    "        if len(approx) == 3:\n",
    "            shape = \"triangle\"\n",
    "\n",
    "        # if the shape has 4 vertices, it is either a square or\n",
    "        # a rectangle\n",
    "        elif len(approx) == 4:\n",
    "            # compute the bounding box of the contour and use the\n",
    "            # bounding box to compute the aspect ratio\n",
    "            (x, y, w, h) = cv2.boundingRect(approx)\n",
    "            ar = w / float(h)\n",
    "\n",
    "            # a square will have an aspect ratio that is approximately\n",
    "            # equal to one, otherwise, the shape is a rectangle\n",
    "            shape = \"square\" if ar >= 0.95 and ar <= 1.05 else \"rectangle\"\n",
    "\n",
    "        # if the shape is a pentagon, it will have 5 vertices\n",
    "        elif len(approx) == 5:\n",
    "            shape = \"pentagon\"\n",
    "\n",
    "        # otherwise, we assume the shape is a circle\n",
    "        else:\n",
    "            shape = \"circle\"\n",
    "\n",
    "        # return the name of the shape\n",
    "        return shape\n",
    "sd = ShapeDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read a new frame:  True\n",
      "(12314, 1, 4)\n",
      "Read a new frame:  True\n",
      "(12309, 1, 4)\n",
      "Read a new frame:  True\n",
      "(12679, 1, 4)\n",
      "Read a new frame:  True\n",
      "(12706, 1, 4)\n",
      "Read a new frame:  True\n",
      "(12751, 1, 4)\n",
      "Read a new frame:  True\n",
      "(12414, 1, 4)\n",
      "Read a new frame:  True\n",
      "(11798, 1, 4)\n",
      "Read a new frame:  True\n",
      "(11900, 1, 4)\n",
      "Read a new frame:  True\n",
      "(12158, 1, 4)\n",
      "Read a new frame:  True\n",
      "(11737, 1, 4)\n",
      "Read a new frame:  True\n",
      "(11953, 1, 4)\n",
      "Read a new frame:  True\n",
      "(12053, 1, 4)\n",
      "Read a new frame:  True\n",
      "(12491, 1, 4)\n",
      "Read a new frame:  True\n",
      "(12229, 1, 4)\n",
      "Read a new frame:  True\n",
      "(12060, 1, 4)\n",
      "Read a new frame:  True\n",
      "(10750, 1, 4)\n",
      "Read a new frame:  True\n",
      "(11787, 1, 4)\n",
      "Read a new frame:  True\n",
      "(12193, 1, 4)\n",
      "Read a new frame:  True\n",
      "(11729, 1, 4)\n",
      "Read a new frame:  True\n",
      "(12003, 1, 4)\n",
      "Read a new frame:  True\n",
      "(12603, 1, 4)\n",
      "Read a new frame:  True\n",
      "(13084, 1, 4)\n",
      "Read a new frame:  True\n",
      "(11584, 1, 4)\n",
      "Read a new frame:  True\n",
      "(12349, 1, 4)\n",
      "Read a new frame:  True\n",
      "(12015, 1, 4)\n",
      "Read a new frame:  True\n",
      "(12003, 1, 4)\n",
      "Read a new frame:  True\n",
      "(12278, 1, 4)\n",
      "Read a new frame:  True\n",
      "(9237, 1, 4)\n",
      "Read a new frame:  True\n",
      "(31478, 1, 4)\n",
      "Read a new frame:  True\n",
      "(33813, 1, 4)\n",
      "Read a new frame:  True\n",
      "(32718, 1, 4)\n",
      "Read a new frame:  True\n",
      "(31434, 1, 4)\n",
      "Read a new frame:  True\n",
      "(31708, 1, 4)\n",
      "Read a new frame:  True\n",
      "(6650, 1, 4)\n",
      "Read a new frame:  True\n",
      "(6771, 1, 4)\n",
      "Read a new frame:  True\n",
      "(6882, 1, 4)\n",
      "Read a new frame:  True\n",
      "(7035, 1, 4)\n",
      "Read a new frame:  True\n",
      "(6881, 1, 4)\n",
      "Read a new frame:  True\n",
      "(28614, 1, 4)\n",
      "Read a new frame:  True\n",
      "(27635, 1, 4)\n",
      "Read a new frame:  True\n",
      "(28073, 1, 4)\n",
      "Read a new frame:  True\n",
      "(15507, 1, 4)\n",
      "Read a new frame:  True\n",
      "(14815, 1, 4)\n",
      "Read a new frame:  True\n",
      "(11901, 1, 4)\n",
      "Read a new frame:  True\n",
      "(4330, 1, 4)\n",
      "Read a new frame:  True\n",
      "(5025, 1, 4)\n",
      "Read a new frame:  True\n",
      "(4170, 1, 4)\n",
      "Read a new frame:  True\n",
      "(4042, 1, 4)\n",
      "Read a new frame:  True\n",
      "(4038, 1, 4)\n",
      "Read a new frame:  True\n",
      "(4709, 1, 4)\n",
      "Read a new frame:  True\n",
      "(10116, 1, 4)\n",
      "Read a new frame:  True\n",
      "(10463, 1, 4)\n",
      "Read a new frame:  True\n",
      "(10471, 1, 4)\n",
      "Read a new frame:  True\n",
      "(10329, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import imutils\n",
    "#Reading the video\n",
    "# vidcap = cv2.VideoCapture(pathFoot)\n",
    "# success,image = vidcap.read()\n",
    "# count = 0\n",
    "# success = True\n",
    "# idx = 0\n",
    "\n",
    "for file in v:\n",
    "    vidcap = cv2.VideoCapture(file)\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    success = True\n",
    "    idx = 0\n",
    "    #Read the video frame by frame\n",
    "    while success:\n",
    "        #converting into hsv image\n",
    "        hsv = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "        #green range\n",
    "        lower_green = np.array([40,40, 40])\n",
    "        upper_green = np.array([70, 255, 255])\n",
    "        #blue range\n",
    "        lower_blue = np.array([110,50,50])\n",
    "        upper_blue = np.array([130,255,255])\n",
    "\n",
    "        #Red range\n",
    "        lower_red = np.array([0,31,255])\n",
    "        upper_red = np.array([176,255,255])\n",
    "\n",
    "        #white range\n",
    "        lower_white = np.array([0,0,0])\n",
    "        upper_white = np.array([0,0,25])\n",
    "\n",
    "        #not white\n",
    "        low = np.array([15, 15, 150])\n",
    "        high = np.array([250, 250, 250])\n",
    "\n",
    "\n",
    "\n",
    "        #Define a mask ranging from lower to uppper\n",
    "        mask = cv2.inRange(hsv, low,high)\n",
    "        #Do masking\n",
    "        res = cv2.bitwise_and(image, image, mask=mask)\n",
    "        #convert to hsv to gray\n",
    "        res_bgr = cv2.cvtColor(res,cv2.COLOR_HSV2BGR)\n",
    "        res_gray = cv2.cvtColor(res,cv2.COLOR_BGR2GRAY)\n",
    "        # gaussian blur is applied to improve the edge detections\n",
    "        res_gray = cv2.GaussianBlur(res_gray, (5, 5), 0)\n",
    "        #Defining a kernel to do morphological operation in threshold image to \n",
    "        #get better output.\n",
    "        kernel = np.ones((13,13),np.uint8)\n",
    "        #thresh = cv2.threshold(res_gray,127,255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "        #thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "        thresh = cv2.threshold(res_gray, 60, 255, cv2.THRESH_BINARY)[1]\n",
    "        print ('Read a new frame: ', success )    # save frame as JPEG file\t\n",
    "        count += 1\n",
    "        \n",
    "       \n",
    "\n",
    "        # Using the Canny filter to get contours\n",
    "        edges = cv2.Canny(res_gray, 1, 10)\n",
    "        # Using the Canny filter with different parameters\n",
    "        edges_high_thresh = cv2.Canny(res_gray, 60, 120)\n",
    "        minLineLength = 1000\n",
    "        maxLineGap = 5\n",
    "        \n",
    "        \n",
    "        lines = cv2.HoughLinesP(res_gray,1,np.pi/180,3,minLineLength,maxLineGap)\n",
    "        print(np.shape(lines))\n",
    "        try:\n",
    "            for l in lines:\n",
    "            #print(np.shape(l) , l)\n",
    "                x1,y1,x2,y2 = l[0,:]\n",
    "                cv2.line(image,(x1,y1),(x2,y2),(0,255,255),2)\n",
    "        except:\n",
    "            print(\"unexcepted error\" , lines)\n",
    "\n",
    "#         thresh = cv2.threshold(image, 60, 255, cv2.THRESH_BINARY)[1]\n",
    "#         cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#         #cnts = imutils.grab_contours(cnts)\n",
    "#         # Stacking the images to print them together\n",
    "#         # For comparison\n",
    "#         #images = np.hstack((gray, edges, edges_high_thresh))\n",
    "#         print(np.shape(cnts))\n",
    "#         for c in cnts:\n",
    "#             try:\n",
    "#                 # compute the center of the contour, then detect the name of the\n",
    "#                 # shape using only the contour\n",
    "#                 M = cv2.moments(c)\n",
    "#                 cX = int((M[\"m10\"] / M[\"m00\"]) )\n",
    "#                 cY = int((M[\"m01\"] / M[\"m00\"]) )\n",
    "#                 shape = sd.detect(c)\n",
    "#                 print(shape)\n",
    "#                 # multiply the contour (x, y)-coordinates by the resize ratio,\n",
    "#                 # then draw the contours and the name of the shape on the image\n",
    "#                 c = c.astype(\"float\")\n",
    "#                 c *= ratio\n",
    "#                 c = c.astype(\"int\")\n",
    "#                 cv2.drawContours(image, [c], -1, (0, 255, 0), 2)\n",
    "#                 cv2.putText(image, shape, (cX, cY), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "#             except:\n",
    "#                 print(\"except the unexcepted\")\n",
    "\n",
    "   \n",
    "        cv2.imshow('Match Detection',edges_high_thresh)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        success,image = vidcap.read()\n",
    "        \n",
    "    \n",
    "vidcap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidcap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
